{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import operator\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the Cornell Movie Dialogues data\n",
    "f = open('movie_lines.txt', 'r',encoding=\"utf-8\", errors=\"ignore\")\n",
    "lines = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "for line in lines:\n",
    "    if len(line.split('+++$+++')) > 4:\n",
    "        dic[int(line.split()[0][1:])] = line.split('+++$+++')[4:]\n",
    "\n",
    "# sort the dialogues into the proper sequence based on the line number 'L...' in the data\n",
    "lst = sorted(dic.items(), key = operator.itemgetter(0))[:10000]\n",
    "\n",
    "# make the queries and replies into different batches based on the films in the data set\n",
    "batches = {}\n",
    "count = 1\n",
    "batch = []\n",
    "for i in range(1, len(lst) + 1):\n",
    "    if i < len(lst):\n",
    "        if lst[i][0] == lst[i-1][0] + 1:\n",
    "            if lst[i-1][1][0].lstrip() not in batch : \n",
    "                batch.append(lst[i-1][1][0].lstrip()) \n",
    "            batch.append(lst[i][1][0].lstrip()) \n",
    "        else:\n",
    "            batches[count] = batch\n",
    "            batch = []\n",
    "        count+=1\n",
    "    else:\n",
    "        pass\n",
    "# make the data into context and target pairs\n",
    "context_and_target = []\n",
    "for ls in batches.values():\n",
    "    if len(ls)%2!=0: ls = ls[:-1]\n",
    "    for i in range(0, len(ls), 2):\n",
    "        context_and_target.append((ls[i], ls[i+1]))\n",
    "context, target = zip(*context_and_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = list(target)\n",
    "\n",
    "# do some basic preprocessing, filter out dialogues with more than 12 words, and in the 12 or lesser words, take only the characters\n",
    "# till one of '!' or '.' or '?' comes\n",
    "import re\n",
    "maxlen = 12\n",
    "for pos,i in enumerate(target):\n",
    "    target[pos] = re.sub('[^a-zA-Z0-9 .,?!]', '', i)\n",
    "    target[pos] = re.sub(' +', ' ', i)\n",
    "    target[pos] = re.sub('([\\w]+)([,;.?!#&-\\'\\\"-]+)([\\w]+)?', r'\\1 \\2 \\3', i)\n",
    "    if len(i.split()) > maxlen:\n",
    "        target[pos] = (' ').join(target[pos].split()[:maxlen])\n",
    "        if '.' in target[pos]: \n",
    "            ind = target[pos].index('.')\n",
    "            target[pos] = target[pos][:ind+1]\n",
    "        if '?' in target[pos]:\n",
    "            ind = target[pos].index('?')\n",
    "            target[pos] = target[pos][:ind+1]\n",
    "        if '!' in target[pos]:\n",
    "            ind = target[pos].index('!')\n",
    "            target[pos] = target[pos][:ind+1]\n",
    "\n",
    "context = list(context)\n",
    "for pos,i in enumerate(context):\n",
    "    context[pos] = re.sub('[^a-zA-Z0-9 .,?!]', '', i)\n",
    "    context[pos] = re.sub(' +', ' ', i)\n",
    "    context[pos] = re.sub('([\\w]+)([,;.?!#&\\'\\\"-]+)([\\w]+)?', r'\\1 \\2 \\3', i)\n",
    "    if len(i.split()) > maxlen:\n",
    "            context[pos] = (' ').join(context[pos].split()[:maxlen])\n",
    "            if '.' in context[pos]:\n",
    "                ind = context[pos].index('.')\n",
    "                context[pos] = context[pos][:ind+1]\n",
    "            if '?' in context[pos]:\n",
    "                ind = context[pos].index('?')\n",
    "                context[pos] = context[pos][:ind+1]\n",
    "            if '!' in context[pos]:\n",
    "                ind = context[pos].index('!')\n",
    "                context[pos] = context[pos][:ind+1]\n",
    "\n",
    "# add Beginning of Sentence (BOS) and End of Sentence (EOS) tags to the 'target' data\n",
    "final_target = ['BOS '+i+' EOS' for i in target]\n",
    "\n",
    "# remove any extra spaces\n",
    "final_target = list(pd.Series(final_target).map(lambda x: re.sub(' +', ' ', x)))\n",
    "context = list(pd.Series(context).map(lambda x: re.sub(' +', ' ', x)))\n",
    "\n",
    "# get all the unique words in the data set with their counts\n",
    "counts = {}\n",
    "for words in final_target+context:\n",
    "    for word in words.split():\n",
    "        counts[word] = counts.get(word,0) + 1\n",
    "\n",
    "# make the dictionary mapping words to indexes\n",
    "word_to_index = {}\n",
    "for pos,i in enumerate(counts.keys()):\n",
    "    word_to_index[i] = pos\n",
    "\n",
    "# reverse dictionary mapping indexes to words\n",
    "index_to_word = {}\n",
    "for k,v in word_to_index.items():\n",
    "    index_to_word[v] = k\t\n",
    "\n",
    "# apply the dictionary to the context and target data\n",
    "final_target = np.array([[word_to_index[w] for w in i.split()] for i in final_target])\n",
    "context = np.array([[word_to_index[w] for w in i.split()] for i in context])\n",
    "\n",
    "# save files\n",
    "np.save('context_indexes', context)\n",
    "\n",
    "np.save('target_indexes', final_target)\n",
    "\n",
    "with open('dictionary.pkl', 'wb') as f:\n",
    "    pickle.dump(word_to_index, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('reverse_dictionary.pkl', 'wb') as f:\n",
    "    pickle.dump(index_to_word, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import operator\n",
    "\n",
    "# load the data\n",
    "context = np.load('context_indexes.npy', allow_pickle = True)\n",
    "final_target = np.load('target_indexes.npy', allow_pickle = True)\n",
    "with open('dictionary.pkl', 'rb') as f:\n",
    "    word_to_index = pickle.load(f)\n",
    "\n",
    "# the indexes of the words start with 0. But when the sequences are padded later on, they too will be zeros.\n",
    "# so, shift all the index values one position to the right, so that 0 is spared, and used only to pad the sequences\n",
    "for i,j in word_to_index.items():\n",
    "    word_to_index[i] = j+1\n",
    "\n",
    "# reverse dictionary\n",
    "index_to_word = {}\n",
    "for k,v in word_to_index.items():\n",
    "    index_to_word[v] = k\n",
    "\n",
    "final_target_1 = final_target\n",
    "context_1 = context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(i) for i in final_target_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([0, 1, 2, 3]),\n",
       "       list([0, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 2, 3]),\n",
       "       list([0, 16, 17, 18, 13, 19, 20, 21, 3]), ...,\n",
       "       list([0, 31, 257, 70, 71, 73, 31, 70, 246, 1649, 106, 10, 1255, 485, 74, 2, 3]),\n",
       "       list([0, 1763, 211, 2, 3]),\n",
       "       list([0, 1763, 301, 31, 955, 10, 368, 434, 7, 119, 368, 275, 1455, 3])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_target_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6462"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 entries completed\n",
      "1000 entries completed\n",
      "2000 entries completed\n",
      "3000 entries completed\n",
      "4000 entries completed\n"
     ]
    }
   ],
   "source": [
    "maxLen = 24\n",
    "\n",
    "# shift the indexes of the context and target arrays too\n",
    "for i in final_target_1:\n",
    "    for pos,j in enumerate(i): i[pos] = j + 1\n",
    "for i in context_1:\n",
    "    for pos,j in enumerate(i): i[pos] = j + 1\n",
    "\n",
    "# read in the 50 dimensional GloVe embeddings\n",
    "def read_glove_vecs(file):\n",
    "    with open(file, 'r') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        \n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            word = line[0]\n",
    "            words.add(word)\n",
    "            word_to_vec_map[word] = np.array(line[1:], dtype=np.float64)\n",
    "            \n",
    "    return words, word_to_vec_map\n",
    "\n",
    "words, word_to_vec_map = read_glove_vecs('glove.6B.50d.txt')\n",
    "\n",
    "# since the indexes start from 1 and not 0, we add 1 to the no. of total words to get the vocabulary size (while initializing \n",
    "# and populating arrays later on, this will be required)\n",
    "vocab_size = len(word_to_index) + 1\n",
    "\n",
    "# initialize the embedding matrix that will be used (50 is the GloVe vector dimension)\n",
    "embedding_matrix = np.zeros((vocab_size, 50))\n",
    "for word,index in word_to_index.items():\n",
    "    try:\n",
    "        embedding_matrix[index, :] = word_to_vec_map[word.lower()]\n",
    "    except: continue\n",
    "\n",
    "# initialize and populate the outputs to the Keras model. The output is the same as the target, but shifted one time step to the left\n",
    "# (teacher forcing)\n",
    "outs = np.zeros((context_1.shape[0], maxLen, vocab_size))\n",
    "for pos,i in enumerate(final_target_1):\n",
    "    for pos1,j in enumerate(i):\n",
    "        if pos1 > 0:\n",
    "            outs[pos, pos1 - 1, j] = 1\n",
    "    if pos%1000 == 0: print ('{} entries completed'.format(pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "\n",
    "# pad the sequences so that they can be fed into the embedding layer\n",
    "final_target_1 = sequence.pad_sequences(final_target_1, maxlen = 24, dtype = 'int32', padding = 'post', truncating = 'post')\n",
    "context_1 = sequence.pad_sequences(context_1, maxlen = 24, dtype = 'int32', padding = 'post', truncating = 'post')\n",
    "\n",
    "\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Input, Dense, LSTM, TimeDistributed\n",
    "from keras.models import Model\n",
    "\n",
    "# load the pre-trained GloVe vectors into the embedding layer\n",
    "embed_layer = Embedding(input_dim = vocab_size, output_dim = 50, trainable = True, )\n",
    "embed_layer.build((None,))\n",
    "embed_layer.set_weights([embedding_matrix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_target (InputLayer)       (None, 24)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_context (InputLayer)      (None, 24)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 24, 50)       323150      input_context[0][0]              \n",
      "                                                                 input_target[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   [(None, 300), (None, 421200      embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_8 (LSTM)                   [(None, 24, 300), (N 421200      embedding_4[1][0]                \n",
      "                                                                 lstm_7[0][1]                     \n",
      "                                                                 lstm_7[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 24, 6463)     1945363     lstm_8[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 3,110,913\n",
      "Trainable params: 3,110,913\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# encoder and decoder gloabal LSTM variables with 300 units\n",
    "LSTM_cell = LSTM(300, return_state = True)\n",
    "LSTM_decoder = LSTM(300, return_state = True, return_sequences = True)\n",
    "# final dense layer that uses TimeDistributed wrapper to generate 'vocab_size' softmax outputs for each time step in the decoder lstm\n",
    "dense = TimeDistributed(Dense(vocab_size, activation = 'softmax'))\n",
    "\n",
    "input_context = Input(shape = (maxLen, ), dtype = 'int32', name = 'input_context')\n",
    "input_target = Input(shape = (maxLen, ), dtype = 'int32', name = 'input_target')\n",
    "\n",
    "# pass the inputs into the embedding layer\n",
    "input_ctx_embed = embed_layer(input_context)\n",
    "input_tar_embed = embed_layer(input_target)\n",
    "\n",
    "# pass the embeddings into the corresponding LSTM layers\n",
    "encoder_lstm, context_h, context_c = LSTM_cell(input_ctx_embed)\n",
    "# the decoder lstm uses the final states from the encoder lstm as the initial state\n",
    "decoder_lstm, _, _ = LSTM_decoder(input_tar_embed, initial_state = [context_h, context_c],)\n",
    "\n",
    "output = dense(decoder_lstm)\n",
    "\n",
    "model = Model([input_context, input_target], output)\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4728/4728 [==============================] - 58s 12ms/step - loss: 2.4356 - acc: 0.0411\n",
      "Epoch 2/100\n",
      "4728/4728 [==============================] - 52s 11ms/step - loss: 2.0773 - acc: 0.0488\n",
      "Epoch 3/100\n",
      "4728/4728 [==============================] - 2345s 496ms/step - loss: 2.0359 - acc: 0.0521\n",
      "Epoch 4/100\n",
      "4728/4728 [==============================] - 56s 12ms/step - loss: 1.9984 - acc: 0.0553\n",
      "Epoch 5/100\n",
      "4728/4728 [==============================] - 7273s 2s/step - loss: 1.9564 - acc: 0.0657\n",
      "Epoch 6/100\n",
      "4728/4728 [==============================] - 9118s 2s/step - loss: 1.9145 - acc: 0.0751\n",
      "Epoch 7/100\n",
      "4728/4728 [==============================] - 65s 14ms/step - loss: 1.8784 - acc: 0.0797\n",
      "Epoch 8/100\n",
      "4728/4728 [==============================] - 54s 11ms/step - loss: 1.8502 - acc: 0.0821\n",
      "Epoch 9/100\n",
      "4728/4728 [==============================] - 61s 13ms/step - loss: 1.8276 - acc: 0.0847\n",
      "Epoch 10/100\n",
      "4728/4728 [==============================] - 63s 13ms/step - loss: 1.8074 - acc: 0.0880\n",
      "Epoch 11/100\n",
      "4728/4728 [==============================] - 64s 14ms/step - loss: 1.7870 - acc: 0.0915\n",
      "Epoch 12/100\n",
      "4728/4728 [==============================] - 65s 14ms/step - loss: 1.7664 - acc: 0.0947\n",
      "Epoch 13/100\n",
      "4728/4728 [==============================] - 66s 14ms/step - loss: 1.7464 - acc: 0.0957\n",
      "Epoch 14/100\n",
      "4728/4728 [==============================] - 72s 15ms/step - loss: 1.7289 - acc: 0.0981\n",
      "Epoch 15/100\n",
      "4728/4728 [==============================] - 67s 14ms/step - loss: 1.7115 - acc: 0.0993\n",
      "Epoch 16/100\n",
      "4728/4728 [==============================] - 70s 15ms/step - loss: 1.6927 - acc: 0.1010\n",
      "Epoch 17/100\n",
      "4728/4728 [==============================] - 68s 14ms/step - loss: 1.6762 - acc: 0.1016\n",
      "Epoch 18/100\n",
      "4728/4728 [==============================] - 68s 14ms/step - loss: 1.6603 - acc: 0.1026\n",
      "Epoch 19/100\n",
      "4728/4728 [==============================] - 70s 15ms/step - loss: 1.6439 - acc: 0.1036\n",
      "Epoch 20/100\n",
      "4728/4728 [==============================] - 75s 16ms/step - loss: 1.6299 - acc: 0.1047\n",
      "Epoch 21/100\n",
      "4728/4728 [==============================] - 81s 17ms/step - loss: 1.6176 - acc: 0.1058\n",
      "Epoch 22/100\n",
      "4728/4728 [==============================] - 90s 19ms/step - loss: 1.6059 - acc: 0.1060\n",
      "Epoch 23/100\n",
      "4728/4728 [==============================] - 101s 21ms/step - loss: 1.5937 - acc: 0.1075\n",
      "Epoch 24/100\n",
      "4728/4728 [==============================] - 107s 23ms/step - loss: 1.5830 - acc: 0.1094\n",
      "Epoch 25/100\n",
      "4728/4728 [==============================] - 102s 22ms/step - loss: 1.5710 - acc: 0.1101\n",
      "Epoch 26/100\n",
      "4728/4728 [==============================] - 94s 20ms/step - loss: 1.5609 - acc: 0.1112\n",
      "Epoch 27/100\n",
      "4728/4728 [==============================] - 90s 19ms/step - loss: 1.5514 - acc: 0.1120\n",
      "Epoch 28/100\n",
      "4728/4728 [==============================] - 88s 19ms/step - loss: 1.5411 - acc: 0.1130\n",
      "Epoch 29/100\n",
      "4728/4728 [==============================] - 88s 19ms/step - loss: 1.5317 - acc: 0.1139\n",
      "Epoch 30/100\n",
      "4728/4728 [==============================] - 87s 18ms/step - loss: 1.5234 - acc: 0.1152\n",
      "Epoch 31/100\n",
      "4728/4728 [==============================] - 88s 19ms/step - loss: 1.5146 - acc: 0.1156\n",
      "Epoch 32/100\n",
      "4728/4728 [==============================] - 90s 19ms/step - loss: 1.5052 - acc: 0.1165\n",
      "Epoch 33/100\n",
      "4728/4728 [==============================] - 95s 20ms/step - loss: 1.4956 - acc: 0.1179\n",
      "Epoch 34/100\n",
      "4728/4728 [==============================] - 100s 21ms/step - loss: 1.4873 - acc: 0.1187\n",
      "Epoch 35/100\n",
      "4728/4728 [==============================] - 107s 23ms/step - loss: 1.4787 - acc: 0.1192\n",
      "Epoch 36/100\n",
      "4728/4728 [==============================] - 111s 23ms/step - loss: 1.4709 - acc: 0.1203\n",
      "Epoch 37/100\n",
      "4728/4728 [==============================] - 115s 24ms/step - loss: 1.4636 - acc: 0.1204\n",
      "Epoch 38/100\n",
      "4728/4728 [==============================] - 119s 25ms/step - loss: 1.4564 - acc: 0.1218\n",
      "Epoch 39/100\n",
      "4728/4728 [==============================] - 122s 26ms/step - loss: 1.4480 - acc: 0.1221\n",
      "Epoch 40/100\n",
      "4728/4728 [==============================] - 125s 27ms/step - loss: 1.4412 - acc: 0.1226\n",
      "Epoch 41/100\n",
      "4728/4728 [==============================] - 128s 27ms/step - loss: 1.4338 - acc: 0.1233\n",
      "Epoch 42/100\n",
      "4728/4728 [==============================] - 125s 26ms/step - loss: 1.4259 - acc: 0.1242\n",
      "Epoch 43/100\n",
      "4728/4728 [==============================] - 122s 26ms/step - loss: 1.4199 - acc: 0.1249\n",
      "Epoch 44/100\n",
      "4728/4728 [==============================] - 119s 25ms/step - loss: 1.4125 - acc: 0.1262\n",
      "Epoch 45/100\n",
      "4728/4728 [==============================] - 119s 25ms/step - loss: 1.4067 - acc: 0.1264\n",
      "Epoch 46/100\n",
      "4728/4728 [==============================] - 119s 25ms/step - loss: 1.3993 - acc: 0.1269\n",
      "Epoch 47/100\n",
      "4728/4728 [==============================] - 118s 25ms/step - loss: 1.3926 - acc: 0.1275\n",
      "Epoch 48/100\n",
      "4728/4728 [==============================] - 6329s 1s/step - loss: 1.3872 - acc: 0.1281\n",
      "Epoch 49/100\n",
      "4728/4728 [==============================] - 3248s 687ms/step - loss: 1.3807 - acc: 0.1285\n",
      "Epoch 50/100\n",
      "4728/4728 [==============================] - 53s 11ms/step - loss: 1.3757 - acc: 0.1290\n",
      "Epoch 51/100\n",
      "4728/4728 [==============================] - 54s 11ms/step - loss: 1.3694 - acc: 0.1295\n",
      "Epoch 52/100\n",
      "1024/4728 [=====>........................] - ETA: 1:03 - loss: 1.3312 - acc: 0.1280"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-85f9e312c9c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcontext_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_target_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit([context_1, final_target_1], outs, epochs = 100, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-82d53f502ba9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#plt.plot(history.history['val_acc'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 正確性の可視化\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['acc'])\n",
    "#plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOS\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Input, Dense, LSTM, TimeDistributed\n",
    "from keras.models import Model\n",
    "\n",
    "# for initial filtering\n",
    "maxLen = 24\n",
    "\n",
    "# import the dictionary\n",
    "with open('dictionary.pkl', 'rb') as f:\n",
    "    word_to_index = pickle.load(f)\n",
    "\n",
    "# import the reverse dictionary\n",
    "with open('reverse_dictionary.pkl', 'rb') as f:\n",
    "    index_to_word = pickle.load(f)\n",
    "\n",
    "# the questi\n",
    "question = 'can you love me'\n",
    "\n",
    "# preprocessing to make the data into the format required by the model, same as during training\n",
    "a = question.split()\n",
    "for pos,i in enumerate(a):\n",
    "    a[pos] = re.sub('[^a-zA-Z0-9 .,?!]', '', i)\n",
    "    a[pos]= re.sub(' +', ' ', i)\n",
    "    a[pos] = re.sub('([\\w]+)([,;.?!#&\\'\\\"-]+)([\\w]+)?', r'\\1 \\2 \\3', i)\n",
    "    if len(i.split()) > maxlen:\n",
    "            a[pos] = (' ').join(a[pos].split()[:maxlen])\n",
    "            if '.' in a[pos]:\n",
    "                ind = a[pos].index('.')\n",
    "                a[pos] = a[pos][:ind+1]\n",
    "            if '?' in a[pos]:\n",
    "                ind = a[pos].index('?')\n",
    "                a[pos] = a[pos][:ind+1]\n",
    "            if '!' in a[pos]:\n",
    "                ind = a[pos].index('!')\n",
    "                a[pos] = a[pos][:ind+1]\n",
    "\n",
    "question = ' '.join(a).split()\n",
    "\n",
    "# make the question into an array of the corresponding indexes\n",
    "question = np.array([word_to_index[w] for w in question])\n",
    "\n",
    "# pad sequences\n",
    "question = sequence.pad_sequences([question], maxlen = 24)\n",
    "\n",
    "# Keras model used to train, so that we define the variables (tensors) that ultimately go into the infernce model\n",
    "input_context = Input(shape = (maxLen, ), dtype = 'int32', name = 'input_context')\n",
    "input_target = Input(shape = (maxLen, ), dtype = 'int32', name = 'output_context')\n",
    "\n",
    "input_ctx_embed = embed_layer(input_context)\n",
    "input_tar_embed = embed_layer(input_target)\n",
    "\n",
    "encoder_lstm, context_h, context_c = LSTM_cell(input_ctx_embed)\n",
    "decoder_lstm, h, _ = LSTM_decoder(input_tar_embed, initial_state = [context_h, context_c],)\n",
    "\n",
    "output = dense(decoder_lstm)\n",
    "\n",
    "# Define the model for the input (question). Returns the final state vectors of the encoder LSTM\n",
    "context_model = Model(input_context, [context_h, context_c])\n",
    "\n",
    "# define the inputs for the decoder LSTM\n",
    "target_h = Input(shape = (300, ))\n",
    "target_c = Input(shape = (300, ))\n",
    "\n",
    "# the decoder LSTM. Takes in the embedding of the initial word passed as input into the decoder model (the 'BOS' tag), \n",
    "# along with the final states of the encoder model, to output the corresponding sequences for 'BOS', and the new LSTM states.  \n",
    "target, h, c = LSTM_decoder(input_tar_embed, initial_state = [target_h, target_c])\n",
    "output = dense(target)\n",
    "target_model = Model([input_target, target_h, target_c], [output, h, c])\n",
    "\n",
    "# pass in the question to the encoder LSTM, to get the final encoder states of the encoder LSTM\n",
    "question_h, question_c = context_model.predict(question)\n",
    "\n",
    "# initialize the answer that will be generated for the 'BOS' input. Since we have used pre-padding for padding sequences,\n",
    "# the last token in the 'answer' variable is initialised with the index for 'BOS'.\n",
    "answer = np.zeros((1, maxLen))\n",
    "answer[0, -1] = word_to_index['BOS']\n",
    "\n",
    "# i keeps track of the length of the generated answer. This won't allow the model to genrate sequences with more than 20 words.\n",
    "i = 1\n",
    "\n",
    "# make a new list to store the words generated at each time step\n",
    "answer_1 = []\n",
    "\n",
    "# flag to stop the model when 'EOS' tag is generated or when 20 time steps have passed.\n",
    "flag = 0\n",
    "\n",
    "# run the inference model\n",
    "while flag != 1:\n",
    "    # make predictions for the given input token and encoder states\n",
    "    prediction, prediction_h, prediction_c = target_model.predict([answer, question_h, question_c])\n",
    "    \n",
    "    # from the generated predictions of shape (num_examples, maxLen, vocab_size), find the token with max probability\n",
    "    token_arg = np.argmax(prediction[0, -1, :])\n",
    "    \n",
    "    # append the corresponding word of the index to the answer_1 list\n",
    "    answer_1.append(index_to_word[token_arg])\n",
    "    \n",
    "    # set flag to 1 if 'EOS' token is generated or 20 time steps have passed\n",
    "    if token_arg == word_to_index['EOS'] or i > 24:\n",
    "        flag = 1\n",
    "    # re-initialise the answer variable, and set the last token to the output of the current time step. This is then passed\n",
    "    # as input to the next time step, along with the LSTM states of the current time step\n",
    "    answer = np.zeros((1,maxLen))\n",
    "    answer[0, -1] = token_arg\n",
    "    question_h = prediction_h\n",
    "    question_c = prediction_c\n",
    "    \n",
    "    # increment the count of the loop\n",
    "    i+=1\n",
    "    \n",
    " # print the answer generated for the given question\n",
    "print (' '.join(answer_1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "452"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
